<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>A guide to mathematically comparing Stable Diffusion models | Caleb Mullan's Site</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="Introduction A Stable Diffusion model, whether a complete copy or a LoRa, is just a Pytorch model - and a Pytorch model like any neural net, is just a series of floating point numbers. These are contained within tensors, a form of array, and most models exist as a list of tensors of varying shapes, sizes, and dimensions. Being able to compare them is useful for any form of statistical analysis, or just calculating useful metrics like average difference of values, like we will here."><meta name=generator content="Hugo 0.111.3"><meta name=robots content="noindex, nofollow"><link rel=stylesheet href=../../ananke/css/main.min.css><meta property="og:title" content="A guide to mathematically comparing Stable Diffusion models"><meta property="og:description" content="Introduction A Stable Diffusion model, whether a complete copy or a LoRa, is just a Pytorch model - and a Pytorch model like any neural net, is just a series of floating point numbers. These are contained within tensors, a form of array, and most models exist as a list of tensors of varying shapes, sizes, and dimensions. Being able to compare them is useful for any form of statistical analysis, or just calculating useful metrics like average difference of values, like we will here."><meta property="og:type" content="article"><meta property="og:url" content="//bemuseed.github.io/posts/flattening-unflattening-stable-diffusion-models/flattening-unflattening-stable-diffusion-models.html"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-02-03T10:42:09+00:00"><meta property="article:modified_time" content="2023-02-03T10:42:09+00:00"><meta property="og:site_name" content="Caleb Mullan's Site"><meta itemprop=name content="A guide to mathematically comparing Stable Diffusion models"><meta itemprop=description content="Introduction A Stable Diffusion model, whether a complete copy or a LoRa, is just a Pytorch model - and a Pytorch model like any neural net, is just a series of floating point numbers. These are contained within tensors, a form of array, and most models exist as a list of tensors of varying shapes, sizes, and dimensions. Being able to compare them is useful for any form of statistical analysis, or just calculating useful metrics like average difference of values, like we will here."><meta itemprop=datePublished content="2023-02-03T10:42:09+00:00"><meta itemprop=dateModified content="2023-02-03T10:42:09+00:00"><meta itemprop=wordCount content="685"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="A guide to mathematically comparing Stable Diffusion models"><meta name=twitter:description content="Introduction A Stable Diffusion model, whether a complete copy or a LoRa, is just a Pytorch model - and a Pytorch model like any neural net, is just a series of floating point numbers. These are contained within tensors, a form of array, and most models exist as a list of tensors of varying shapes, sizes, and dimensions. Being able to compare them is useful for any form of statistical analysis, or just calculating useful metrics like average difference of values, like we will here."></head><body class="ma0 avenir bg-near-white"><header><div class=bg-black><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=../../ class="f3 fw2 hover-white no-underline white-90 dib">Caleb Mullan's Site</a><div class="flex-l items-center"><ul class="pl0 mr3"><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=../../posts.html title="Posts page">Posts</a></li></ul><div class=ananke-socials><a href=https://github.com/Bemuseed target=_blank rel=noopener class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" aria-label="follow on GitHub——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div></div></div></nav></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">POSTS</aside><div id=sharing class="mt3 ananke-socials"></div><h1 class="f1 athelas mt3 mb1">A guide to mathematically comparing Stable Diffusion models</h1><p class=tracked>By <strong>Caleb Mullan</strong></p><time class="f6 mv4 dib tracked" datetime=2023-02-03T10:42:09Z>February 3, 2023</time></header><div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><h2 id=introduction>Introduction</h2><p>A Stable Diffusion model, whether a complete copy or a LoRa, is just a Pytorch model - and a Pytorch model like any neural net, is just a series of floating point numbers. These are contained within tensors, a form of array, and most models exist as a list of tensors of varying shapes, sizes, and dimensions. Being able to compare them is useful for any form of statistical analysis, or just calculating useful metrics like average difference of values, like we will here.</p><p><img src=images/neural_net_weights.png alt="A neural net"></p><p>In this guide, you&rsquo;ll be shown how to convert a PyTorch model into a one-dimensional array of floating point numbers, and back again, in the following process:</p><ul><li>Extracting the structure from a .ckpt file.</li><li>&ldquo;Flattening&rdquo; the structure into a 1D Numpy array</li><li>Reformatting this array back to the original format of the model.</li><li>Repackaging this into a .ckpt file once more.</li></ul><h2 id=extraction>Extraction</h2><p>A .ckpt file is just a Python dictionary that&rsquo;s been saved to disk using the &lsquo;pickle&rsquo; module. The Pytorch module has <a href=https://pytorch.org/docs/stable/generated/torch.load.html#torch.load>a load method</a> for loading this into a program. Run the following code in a REPL:</p><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#fe8019>&gt;&gt;&gt;</span> <span style=color:#fe8019>import</span> torch
</span></span><span style=display:flex><span><span style=color:#fe8019>&gt;&gt;&gt;</span> tensor_dict <span style=color:#fe8019>=</span> torch<span style=color:#fe8019>.</span>load(<span style=color:#b8bb26>&#34;&lt;name-of-model&gt;.ckpt&#34;</span>, map_location<span style=color:#fe8019>=</span><span style=color:#b8bb26>&#34;cpu&#34;</span>)
</span></span></code></pre></div><p>Feel free to look at the dictionary. If you&rsquo;re working with a LoRa, it&rsquo;s a bunch of key-value pairs where the keys are strings and the values are floating point numbers. If you have a full SD model, it consists of a single key-value pair, with the key being the string <code>state_dict</code>, and the value being another dictionary. <em>That</em> dictionary contains 1131 key-value pairs, each value being the Pytorch <code>Tensor</code> objects that contain the numbers we&rsquo;re interested in.</p><p>All further instructions will be for LoRas, just add &ldquo;[state_dict]&rdquo; to references to the dictionary to get it working for a full model.</p><p>Now that we know the structure, we can extract those <code>Tensor</code> objects into a list, like so:</p><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#fe8019>&gt;&gt;&gt;</span> tensors <span style=color:#fe8019>=</span> <span style=color:#fabd2f>list</span>(tensor_dict<span style=color:#fe8019>.</span>values()) 
</span></span></code></pre></div><p>We&rsquo;re also going to need to keep that dictionary structure for later when we want to convert back to a .ckpt file. To simplify things, and free up some memory, we&rsquo;ll set all the values to 0, and keep the keys the same.</p><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#fe8019>&gt;&gt;&gt;</span> new_dict <span style=color:#fe8019>=</span> <span style=color:#fabd2f>dict</span>()
</span></span><span style=display:flex><span><span style=color:#fe8019>&gt;&gt;&gt;</span> <span style=color:#fe8019>for</span> k <span style=color:#fe8019>in</span> <span style=color:#fabd2f>list</span>(tensor_dict<span style=color:#fe8019>.</span>keys()): 
</span></span><span style=display:flex><span><span style=color:#fe8019>...</span> 	new_dict[k] <span style=color:#fe8019>=</span> <span style=color:#d3869b>0</span> 
</span></span></code></pre></div><h2 id=flattening>Flattening</h2><p>Now to actually flatten the tensors. First, we&rsquo;ll convert them all to Numpy arrays, which <code>Pytorch</code> provides an in-built method for.</p><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#fe8019>&gt;&gt;&gt;</span> tensors <span style=color:#fe8019>=</span> [t<span style=color:#fe8019>.</span>numpy() <span style=color:#fe8019>for</span> t <span style=color:#fe8019>in</span> tensors]
</span></span></code></pre></div><p>Then, we perform the flattening itself. First we&rsquo;ll make the following function to take a single tensor array and flatten it:</p><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#fe8019>def</span> <span style=color:#fabd2f>flatten</span>(matrix):
</span></span><span style=display:flex><span>    shapes <span style=color:#fe8019>=</span> [a<span style=color:#fe8019>.</span>shape <span style=color:#fe8019>for</span> a <span style=color:#fe8019>in</span> matrix]
</span></span><span style=display:flex><span>    offsets <span style=color:#fe8019>=</span> [a<span style=color:#fe8019>.</span>size <span style=color:#fe8019>for</span> a <span style=color:#fe8019>in</span> matrix]
</span></span><span style=display:flex><span>    offsets <span style=color:#fe8019>=</span> numpy<span style=color:#fe8019>.</span>cumsum([<span style=color:#d3869b>0</span>] <span style=color:#fe8019>+</span> offsets)
</span></span><span style=display:flex><span>    result <span style=color:#fe8019>=</span> numpy<span style=color:#fe8019>.</span>concatenate([a<span style=color:#fe8019>.</span>flat <span style=color:#fe8019>for</span> a <span style=color:#fe8019>in</span> matrix])
</span></span><span style=display:flex><span>    <span style=color:#fe8019>return</span> result, shapes, offsets
</span></span></code></pre></div><p>While you could type that out in the REPL, I&rsquo;d recommend you put this in it&rsquo;s own .py file. Then you can use it in a REPL with an import or with</p><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#fe8019>&gt;&gt;&gt;</span> exec(<span style=color:#fabd2f>open</span>(<span style=color:#b8bb26>&#34;&lt;file&gt;.py).read())</span>
</span></span></code></pre></div><p>Then, we use this function in another function that applies this method to a list of different matrices:</p><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#fe8019>def</span> <span style=color:#fabd2f>list_flatten</span>(matrix_list):
</span></span><span style=display:flex><span>    result <span style=color:#fe8019>=</span> numpy<span style=color:#fe8019>.</span>array([])
</span></span><span style=display:flex><span>    shapes <span style=color:#fe8019>=</span> []
</span></span><span style=display:flex><span>    offsets <span style=color:#fe8019>=</span> []
</span></span><span style=display:flex><span>    limits <span style=color:#fe8019>=</span> [<span style=color:#d3869b>0</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#fe8019>for</span> a <span style=color:#fe8019>in</span> matrix_list:
</span></span><span style=display:flex><span>        r, s, o <span style=color:#fe8019>=</span> flatten(a)
</span></span><span style=display:flex><span>        result <span style=color:#fe8019>=</span> numpy<span style=color:#fe8019>.</span>append(result, r)
</span></span><span style=display:flex><span>        shapes<span style=color:#fe8019>.</span>append(s)
</span></span><span style=display:flex><span>        offsets<span style=color:#fe8019>.</span>append(o)
</span></span><span style=display:flex><span>        limits<span style=color:#fe8019>.</span>append(<span style=color:#fabd2f>len</span>(result))
</span></span><span style=display:flex><span>    <span style=color:#fe8019>return</span> result, shapes, offsets, limits
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#fe8019>&gt;&gt;&gt;</span> flattened, shapes, offsets, limits <span style=color:#fe8019>=</span> list_flatten(tensors)
</span></span></code></pre></div><p>Now you have your 1D array! We can now manipulate it as we please. For example, let&rsquo;s see how many floating point numbers are in the whole model:</p><p><img src=images/tensor_size.png alt="The total number of numbers in the model"></p><h2 id=comparing>Comparing</h2><p>Now that we have our flattened data, comparing is fairly simple:</p><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>diffs <span style=color:#fe8019>=</span> numpy<span style=color:#fe8019>.</span>abs(model_a_weights <span style=color:#fe8019>-</span> model_b_weights)
</span></span><span style=display:flex><span>av_difference <span style=color:#fe8019>=</span> numpy<span style=color:#fe8019>.</span>average(diff)
</span></span></code></pre></div><p>numpy does the heavy lifting here. The subtraction of the two arrays gives an array of every value subtracted by its corresponding value; numpy.abs takes this and sets each number to its absolute value; and numpy.average return the average value for this entire array.</p><h1 id=conclusion>Conclusion</h1><p>Mathematical comparison is a great way to see how different training datasets and parameters affect the training, whether Dreambooth or LoRa. By iterating and averaging these difference values, you can even calculate how different a model is, on average, to a whole set of others.</p><ul class=pa0></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=//bemuseed.github.io/>&copy; Caleb Mullan's Site 2023</a><div><div class=ananke-socials><a href=https://github.com/Bemuseed target=_blank rel=noopener class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" aria-label="follow on GitHub——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div></div></div></footer></body></html>