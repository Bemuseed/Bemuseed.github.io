<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>A Guide to flattening and unflattening Pytorch Models | Caleb's Site</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="Intro A Pytorch model, like any neural net, is essentially a list of floating point numbers in a particular structure. In this guide, you&rsquo;ll be shown how to:
Extract this structure from a .ckpt file. &ldquo;Flatten&rdquo; this structure into a 1D Numpy array Reformat this array back to the original format of the model. Repackage this into a .ckpt file once more. Extraction A .ckpt file is just a Python dictionary that&rsquo;s been saved to disk using the &lsquo;pickle&rsquo; module."><meta name=generator content="Hugo 0.110.0"><meta name=robots content="noindex, nofollow"><link rel=stylesheet href=../ananke/css/main.min.css><meta property="og:title" content="A Guide to flattening and unflattening Pytorch Models"><meta property="og:description" content="Intro A Pytorch model, like any neural net, is essentially a list of floating point numbers in a particular structure. In this guide, you&rsquo;ll be shown how to:
Extract this structure from a .ckpt file. &ldquo;Flatten&rdquo; this structure into a 1D Numpy array Reformat this array back to the original format of the model. Repackage this into a .ckpt file once more. Extraction A .ckpt file is just a Python dictionary that&rsquo;s been saved to disk using the &lsquo;pickle&rsquo; module."><meta property="og:type" content="article"><meta property="og:url" content="//bemuseed.github.io/posts/flattening-unflattening-stable-diffusion-models.html"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-02-03T10:42:09+00:00"><meta property="article:modified_time" content="2023-02-03T10:42:09+00:00"><meta property="og:site_name" content="Caleb's Site"><meta itemprop=name content="A Guide to flattening and unflattening Pytorch Models"><meta itemprop=description content="Intro A Pytorch model, like any neural net, is essentially a list of floating point numbers in a particular structure. In this guide, you&rsquo;ll be shown how to:
Extract this structure from a .ckpt file. &ldquo;Flatten&rdquo; this structure into a 1D Numpy array Reformat this array back to the original format of the model. Repackage this into a .ckpt file once more. Extraction A .ckpt file is just a Python dictionary that&rsquo;s been saved to disk using the &lsquo;pickle&rsquo; module."><meta itemprop=datePublished content="2023-02-03T10:42:09+00:00"><meta itemprop=dateModified content="2023-02-03T10:42:09+00:00"><meta itemprop=wordCount content="638"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="A Guide to flattening and unflattening Pytorch Models"><meta name=twitter:description content="Intro A Pytorch model, like any neural net, is essentially a list of floating point numbers in a particular structure. In this guide, you&rsquo;ll be shown how to:
Extract this structure from a .ckpt file. &ldquo;Flatten&rdquo; this structure into a 1D Numpy array Reformat this array back to the original format of the model. Repackage this into a .ckpt file once more. Extraction A .ckpt file is just a Python dictionary that&rsquo;s been saved to disk using the &lsquo;pickle&rsquo; module."></head><body class="ma0 avenir bg-near-white"><header><div class=bg-black><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=../ class="f3 fw2 hover-white no-underline white-90 dib">Caleb's Site</a><div class="flex-l items-center"><ul class="pl0 mr3"><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=../posts.html title="Posts page">Posts</a></li></ul><div class=ananke-socials><a href=https://github.com/Bemuseed target=_blank rel=noopener class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" aria-label="follow on GitHub——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div></div></div></nav></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">POSTS</aside><div id=sharing class="mt3 ananke-socials"></div><h1 class="f1 athelas mt3 mb1">A Guide to flattening and unflattening Pytorch Models</h1><p class=tracked>By <strong>Caleb Mullan</strong></p><time class="f6 mv4 dib tracked" datetime=2023-02-03T10:42:09Z>February 3, 2023</time></header><div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><h1 id=intro>Intro</h1><p>A Pytorch model, like any neural net, is essentially a list of floating point numbers in a particular structure. In this guide, you&rsquo;ll be shown how to:</p><ul><li>Extract this structure from a .ckpt file.</li><li>&ldquo;Flatten&rdquo; this structure into a 1D Numpy array</li><li>Reformat this array back to the original format of the model.</li><li>Repackage this into a .ckpt file once more.</li></ul><h1 id=extraction>Extraction</h1><p>A .ckpt file is just a Python dictionary that&rsquo;s been saved to disk using the &lsquo;pickle&rsquo; module. The Pytorch module has <a href=https://pytorch.org/docs/stable/generated/torch.load.html#torch.load>a load method</a> for loading this into a program. Run the following code in a REPL:</p><pre tabindex=0><code>&gt;&gt;&gt; import torch
&gt;&gt;&gt; tensor_dict = torch.load(&#34;&lt;name-of-model&gt;.ckpt&#34;, map_location=&#34;cpu&#34;)
</code></pre><p>Feel free to look at the dictionary. It consists of a single key-value pair, with the key being the string <code>state_dict</code>, and the value being another dictionary. <em>That</em> dictionary contains 1131 key-value pairs, each value being the Pytorch <code>Tensor</code> objects that contain the numbers we&rsquo;re interested in.</p><p>Now that we know the structure, we can extract those <code>Tensor</code> objects into a list, like so:</p><pre tabindex=0><code>&gt;&gt;&gt; tensors = list(tensor_dict[&#39;state_dict&#39;].values()) 
</code></pre><p>We&rsquo;re also going to need to keep that dictionary structure for later when we want to convert back to a .ckpt file. To simplify things, and free up some memory, we&rsquo;ll set all the values to 0, and keep the keys the same.</p><pre tabindex=0><code>&gt;&gt;&gt; new_dict = {&#39;state_dict: dict()} 
&gt;&gt;&gt; for k in list(tensor_dict[&#39;state_dict&#39;].keys()): 
... 	new_dict[&#39;state_dict&#39;][k] = 0 
</code></pre><h1 id=flattening>Flattening</h1><p>Now to actually flatten the tensors. First, we&rsquo;ll convert them all to Numpy arrays, which <code>Pytorch</code> provides an in-built method for.</p><pre tabindex=0><code>&gt;&gt;&gt; tensors = [t.numpy() for t in tensors]
</code></pre><p>Then, we perform the flattening itself. First we&rsquo;ll make the following function to take a single tensor array and flatten it:</p><pre tabindex=0><code>def flatten(matrix):
    shapes = [a.shape for a in matrix]
    offsets = [a.size for a in matrix]
    offsets = numpy.cumsum([0] + offsets)
    result = numpy.concatenate([a.flat for a in matrix])
    return result, shapes, offsets
</code></pre><p>While you could type that out in the REPL, I&rsquo;d recommend you put this in it&rsquo;s own .py file. Then you can use it in a REPL with an import or with</p><pre tabindex=0><code>&gt;&gt;&gt; exec(open(&#34;&lt;file&gt;.py).read())
</code></pre><p>Then, we use this function in another function that applies this method to a list of different matrices:</p><pre tabindex=0><code>def list_flatten(matrix_list):
    result = numpy.array([])
    shapes = []
    offsets = []
    limits = [0]

    for a in matrix_list:
        r, s, o = flatten(a)
        result = numpy.append(result, r)
        shapes.append(s)
        offsets.append(o)
        limits.append(len(result))
    return result, shapes, offsets, limits
</code></pre><pre tabindex=0><code>&gt;&gt;&gt; flattened, shapes, offsets, limits = list_flatten(tensors)
</code></pre><p>This should give the desired 1D array of numbers, for you to use as you need to.</p><h1 id=unflattening>Unflattening</h1><p>This part is the more complex of the two. We&rsquo;ll need two more functions, like these:</p><pre tabindex=0><code>def unflatten(flattened, shapes, offsets):
    restored = numpy.array([numpy.reshape(flattened[offsets[i]:offsets[i + 1]], shape)
            for i, shape in enumerate(shapes)])

def list_unflatten(flattened, shapes, offsets, limits):
    unflattened = []
    for i in range(len(limits) - 1):
        section = flattened[limits[i]:limits[i+1]]
        unflattened.append(unflatten(section, shapes[i], offsets[i]))
    return unflattened
</code></pre><p>Which you can then use with the output of the flattening functions:</p><pre tabindex=0><code>&gt;&gt;&gt; restored_tensor_list = list_unflatten(flattened, shapes, offsets, limits)
</code></pre><p>A word of warning - running this part will eat up your RAM. Make sure to free some up before running it. Linux users without a lot of memory who can increase their swap partition size should do so.</p><h1 id=repackaging>Repackaging</h1><p>And finally, to take our modified tensor list and place it in a new .ckpt file, we first return it to its original dictionary format. First, we convert the arrays back into <code>Tensor</code> objects:</p><pre tabindex=0><code>&gt;&gt;&gt; tensors = [torch.from_numpy(nd) for nd in tensors]
</code></pre><p>Then we use that <code>dict_template</code> dictionary we prepared earlier, and populate it with our new tensor data:</p><pre tabindex=0><code>&gt;&gt;&gt; t_counter = 0
&gt;&gt;&gt; new_dict = {&#39;state_dict&#39;: dict()}
&gt;&gt;&gt; for k in list(dict_template[&#39;state_dict&#39;].keys()):
&gt;&gt;&gt; 	new_dict[&#39;state_dict&#39;][k] = tensors[t_counter]
&gt;&gt;&gt;     t_counter += 1
</code></pre><p>And finally, we use the Pytorch save method to produce our new .ckpt file.</p><pre tabindex=0><code>&gt;&gt;&gt; torch.save(new_dict, &#34;my_model&#34;.ckpt)
</code></pre><ul class=pa0></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=//bemuseed.github.io/>&copy; Caleb's Site 2023</a><div><div class=ananke-socials><a href=https://github.com/Bemuseed target=_blank rel=noopener class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" aria-label="follow on GitHub——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div></div></div></footer></body></html>