<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Creating Novel Art Styles With AI | Caleb Mullan's Site</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="The goal of this project is to enable the creation of new, appealing art-styles with AI. This is to be done by manipulating Stable Diffusion models trained on pre-existing, specific styles. The aim is that we&rsquo;ll be able to move around the &lsquo;space&rsquo; of all such models, using both model merging and Principal Component Analysis.
Fine-tuning a model with Dreambooth using Google Colab Dreambooth allows a Stable Diffusion model to be further trained upon a particular subject (a character or art-style)."><meta name=generator content="Hugo 0.111.1"><meta name=robots content="noindex, nofollow"><link rel=stylesheet href=../../ananke/css/main.min.css><meta property="og:title" content="Creating Novel Art Styles With AI"><meta property="og:description" content="The goal of this project is to enable the creation of new, appealing art-styles with AI. This is to be done by manipulating Stable Diffusion models trained on pre-existing, specific styles. The aim is that we&rsquo;ll be able to move around the &lsquo;space&rsquo; of all such models, using both model merging and Principal Component Analysis.
Fine-tuning a model with Dreambooth using Google Colab Dreambooth allows a Stable Diffusion model to be further trained upon a particular subject (a character or art-style)."><meta property="og:type" content="article"><meta property="og:url" content="//bemuseed.github.io/posts/novelartstyleswithai/novelartstyleswithai.html"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-03-02T01:08:11+00:00"><meta property="article:modified_time" content="2023-03-02T01:08:11+00:00"><meta property="og:site_name" content="Caleb Mullan's Site"><meta itemprop=name content="Creating Novel Art Styles With AI"><meta itemprop=description content="The goal of this project is to enable the creation of new, appealing art-styles with AI. This is to be done by manipulating Stable Diffusion models trained on pre-existing, specific styles. The aim is that we&rsquo;ll be able to move around the &lsquo;space&rsquo; of all such models, using both model merging and Principal Component Analysis.
Fine-tuning a model with Dreambooth using Google Colab Dreambooth allows a Stable Diffusion model to be further trained upon a particular subject (a character or art-style)."><meta itemprop=datePublished content="2023-03-02T01:08:11+00:00"><meta itemprop=dateModified content="2023-03-02T01:08:11+00:00"><meta itemprop=wordCount content="851"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Creating Novel Art Styles With AI"><meta name=twitter:description content="The goal of this project is to enable the creation of new, appealing art-styles with AI. This is to be done by manipulating Stable Diffusion models trained on pre-existing, specific styles. The aim is that we&rsquo;ll be able to move around the &lsquo;space&rsquo; of all such models, using both model merging and Principal Component Analysis.
Fine-tuning a model with Dreambooth using Google Colab Dreambooth allows a Stable Diffusion model to be further trained upon a particular subject (a character or art-style)."></head><body class="ma0 avenir bg-near-white"><header><div class=bg-black><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=../../ class="f3 fw2 hover-white no-underline white-90 dib"><img src=../../img/avatar.png class="w100 mw5-ns" alt="Caleb Mullan's Site"></a><div class="flex-l items-center"><ul class="pl0 mr3"><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=../../posts.html title="Posts page">Posts</a></li></ul><div class=ananke-socials><a href=https://github.com/Bemuseed target=_blank rel=noopener class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" aria-label="follow on GitHub——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div></div></div></nav></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">POSTS</aside><div id=sharing class="mt3 ananke-socials"></div><h1 class="f1 athelas mt3 mb1">Creating Novel Art Styles With AI</h1><p class=tracked>By <strong>Caleb Mullan</strong></p><time class="f6 mv4 dib tracked" datetime=2023-03-02T01:08:11Z>March 2, 2023</time></header><div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>The goal of this project is to enable the creation of new, appealing art-styles with AI. This is to be done by manipulating Stable Diffusion models trained on pre-existing, specific styles. The aim is that we&rsquo;ll be able to move around the &lsquo;space&rsquo; of all such models, using both model merging and Principal Component Analysis.</p><h1 id=fine-tuning-a-model-with-dreambooth-using-google-colab>Fine-tuning a model with Dreambooth using Google Colab</h1><p><a href=https://arxiv.org/pdf/2208.12242.pdf>Dreambooth</a> allows a Stable Diffusion model to be further trained upon a particular subject (a character or art-style). Many examples can be found on <a href=civit.ai>civit.ai</a>. Training a Dreambooth model requires access to a GPU with sufficient RAM. Rather than doing this with your own hardware, you can offload the task to Google with their Colab service (which is free).</p><p>One such notebook is <a href="https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb#scrollTo=ZnmQYfZilzY6">The Last Ben&rsquo;s</a>. The notebook is fairly self explanatory, but in brief:</p><ul><li>Run the cells for dependencies and accessing your Google Drive (you&rsquo;ll need ~2.1GB of free space)</li><li>Run the cell for downloading the model</li><li>Create a session, with a suitable name</li><li>Prepare your training images<ul><li>Obtain 20-30 images that are good examples of the style you want to train upon</li><li>Use <a href=birme.net>birme.net</a> to crop these to 512x512, in .jpg format, and to name them all with the format <code>&lt;style-name> (x).jpg</code>, where x increments from 1 for each image.</li></ul></li><li>Run the training cell, which shouldn&rsquo;t take overly long</li><li>Run the testing cell, and click on the link it gives you to access the Automatic1111 interface in your browser</li><li>Test the model by putting in prompts and running generate. You can adjust the sampler used, number of samples, etc. A good guide on getting best results can be found <a href=https://old.reddit.com/r/StableDiffusion/comments/x41n87/how_to_get_images_that_dont_suck_a/>here</a>.</li></ul><p>The .ckpt file for you new model should be in your Drive under &lsquo;Fast-Dreambooth&rsquo;. If you want to run this again, or a file you obtained and uploaded to your Drive:</p><ul><li>Run the dependency and Drive access cells</li><li>Use the file explorer on the left to copy the path to the .ckpt file you want</li><li>Run the Testing cell and paste the path into the dialogue box that comes up</li></ul><h1 id=converting-a-model-to-a-flat-array-of-numbers>Converting a model to a flat array of numbers</h1><p>The code for doing this can be found at <a href=https://github.com/Bemuseed/Blog-Git-Repo>this GitHub repo</a>. In order to use PCA, we first have to convert each of our models into a 1D array of its weight values.</p><h2 id=how-its-done>How It&rsquo;s Done</h2><p>Run python from the folder containing the python files. Then:</p><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#fe8019>&gt;&gt;&gt;</span> <span style=color:#fe8019>import</span> flat<span style=color:#fe8019>,</span> tensor_manager
</span></span><span style=display:flex><span><span style=color:#fe8019>&gt;&gt;&gt;</span> tensors, dict_template <span style=color:#fe8019>=</span> tensor_manager<span style=color:#fe8019>.</span>get_tensors_from_file(<span style=color:#b8bb26>&#34;my_model.ckpt&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#fe8019>&gt;&gt;&gt;</span> flattened, s, o, l <span style=color:#fe8019>=</span> flat<span style=color:#fe8019>.</span>list_flatten(tensors)
</span></span></code></pre></div><p>Then, to convert a flattened model back:</p><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#fe8019>&gt;&gt;&gt;</span> restored <span style=color:#fe8019>=</span> flat<span style=color:#fe8019>.</span>list_unflatten(flattened, s, o, l)
</span></span><span style=display:flex><span><span style=color:#fe8019>&gt;&gt;&gt;</span> t_dict <span style=color:#fe8019>=</span> tensor_manager<span style=color:#fe8019>.</span>restore_tensor_dict(restored, dict_template)
</span></span><span style=display:flex><span><span style=color:#fe8019>&gt;&gt;&gt;</span> <span style=color:#fe8019>import</span> torch
</span></span><span style=display:flex><span><span style=color:#fe8019>&gt;&gt;&gt;</span> torch<span style=color:#fe8019>.</span>save(t_dict, <span style=color:#fabd2f>open</span>(<span style=color:#b8bb26>&#34;new_model.ckpt&#34;</span>, <span style=color:#b8bb26>&#34;wb&#34;</span>))
</span></span></code></pre></div><h2 id=how-it-works>How It Works</h2><p>Some parts of the code need explained.</p><h3 id=tensor_managerpy>tensor_manager.py</h3><p>Every .ckpt file is simply a <a href=https://docs.python.org/3/library/pickle.html>pickled</a> PyTorch model, which can be loaded back into an object using <a href=https://pytorch.org/docs/stable/generated/torch.load.html#torch.load>torch.load</a>. These objects are just dictionaries, with one key, <code>state_dict</code>, which corresponds to another dictionary whose values are the model tensors.</p><p>The <code>get_tensors</code> method iterates through those values and puts them in a list, and also sets them to 0 to create a &rsquo;template&rsquo; that can be used later to repackage the (modified) tensors back into the right format, using <code>restore_tensor_dict</code> (which simply reverses the process).</p><h3 id=flatpy>flat.py</h3><p>First, the <code>flatten</code> function in flat.py.</p><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#fe8019>def</span> <span style=color:#fabd2f>flatten</span>(matrix):
</span></span><span style=display:flex><span>    shapes <span style=color:#fe8019>=</span> [a<span style=color:#fe8019>.</span>shape <span style=color:#fe8019>for</span> a <span style=color:#fe8019>in</span> matrix]
</span></span><span style=display:flex><span>    offsets <span style=color:#fe8019>=</span> [a<span style=color:#fe8019>.</span>size <span style=color:#fe8019>for</span> a <span style=color:#fe8019>in</span> matrix]
</span></span><span style=display:flex><span>    offsets <span style=color:#fe8019>=</span> numpy<span style=color:#fe8019>.</span>cumsum([<span style=color:#d3869b>0</span>] <span style=color:#fe8019>+</span> offsets)
</span></span><span style=display:flex><span>    result <span style=color:#fe8019>=</span> numpy<span style=color:#fe8019>.</span>concatenate([a<span style=color:#fe8019>.</span>flat <span style=color:#fe8019>for</span> a <span style=color:#fe8019>in</span> matrix])
</span></span><span style=display:flex><span>    <span style=color:#fe8019>return</span> result, shapes, offsets
</span></span></code></pre></div><ol><li>The function first creates a list of shapes, where each shape corresponds to the shape of the corresponding numpy array in the input list. This is done using a list comprehension and the &ldquo;shape&rdquo; attribute of numpy arrays.</li><li>The function then creates a list of offsets, where each offset corresponds to the size (i.e., the number of elements) of the corresponding numpy array in the input list. This is done using a list comprehension and the &ldquo;size&rdquo; attribute of numpy arrays.</li><li>The offsets list is then converted to a cumulative sum using numpy.cumsum(), giving the starting index of each numpy array in the flattened output.</li><li>The function then flattens each numpy array in the input list using the &ldquo;flat&rdquo; attribute of numpy arrays and concatenates them together using numpy.concatenate().</li><li>Finally, the function returns the flattened output, the list of shapes, and the list of offsets.</li></ol><p>The shapes and offsets we get from this are then put to use when we <code>unflatten</code>:</p><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#fe8019>def</span> <span style=color:#fabd2f>unflatten</span>(flattened, shapes, offsets):
</span></span><span style=display:flex><span>    restored <span style=color:#fe8019>=</span> numpy<span style=color:#fe8019>.</span>array([numpy<span style=color:#fe8019>.</span>reshape(flattened[offsets[i]:offsets[i <span style=color:#fe8019>+</span> <span style=color:#d3869b>1</span>]], shape) <span style=color:#fe8019>for</span> i, shape <span style=color:#fe8019>in</span> <span style=color:#fabd2f>enumerate</span>(shapes)])
</span></span><span style=display:flex><span>    <span style=color:#fe8019>return</span> restored
</span></span></code></pre></div><p>This part is better understood if we expand it into a longer for-loop:</p><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>restored <span style=color:#fe8019>=</span> numpy<span style=color:#fe8019>.</span>array(dtype<span style=color:#fe8019>=</span>numpy<span style=color:#fe8019>.</span>float16)
</span></span><span style=display:flex><span><span style=color:#fe8019>for</span> i, shape <span style=color:#fe8019>in</span> <span style=color:#fabd2f>enumerate</span>(shapes):
</span></span><span style=display:flex><span>	slice_start <span style=color:#fe8019>=</span> offsets[i]
</span></span><span style=display:flex><span>	slice_end <span style=color:#fe8019>=</span> offsets[i <span style=color:#fe8019>+</span> <span style=color:#d3869b>1</span>]
</span></span><span style=display:flex><span>	<span style=color:#fabd2f>slice</span> <span style=color:#fe8019>=</span> flattened[slice_start:slice_end]
</span></span><span style=display:flex><span>	restored_slice <span style=color:#fe8019>=</span> numpy<span style=color:#fe8019>.</span>reshape(<span style=color:#fabd2f>slice</span>, shape)
</span></span><span style=display:flex><span>	restored <span style=color:#fe8019>=</span> numpy<span style=color:#fe8019>.</span>append(restored, restored_slice)
</span></span></code></pre></div><p><code>list_flatten</code> simply iterates <code>flatten</code> over a list of arrays (which is what we are given when we run <code>get_tensors_from_file</code>), saving an additional list called <code>limits</code> that marks where in the flattened array the individual arrays start and end. These limits are used to mark each <code>section</code> used in <code>list_unflatten</code>, which also iterates its non-list companion function.</p><ul class=pa0></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=//bemuseed.github.io/>&copy; Caleb Mullan's Site 2023</a><div><div class=ananke-socials><a href=https://github.com/Bemuseed target=_blank rel=noopener class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" aria-label="follow on GitHub——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div></div></div></footer></body></html>